# Yapay Zeka ile YÃ¼z TanÄ±ma ve Fizyonomi Analizi Yol HaritasÄ±

Bu belge, mevcut uygulamanÄ±n yapay zeka yeteneklerini geliÅŸtirmek ve daha ileri seviye bir fizyonomi analiz sistemi oluÅŸturmak iÃ§in izlenecek adÄ±mlarÄ± iÃ§erir.

## Faz 1: Veri Toplama ve HazÄ±rlÄ±k (1-2 Ay)

Yapay zeka modellerinin baÅŸarÄ±sÄ±, kaliteli ve etiketli veriye baÄŸlÄ±dÄ±r.

### 1.1. Veri Seti OluÅŸturma
- **Hedef:** 10.000+ yÃ¼z fotoÄŸrafÄ±ndan oluÅŸan Ã§eÅŸitli bir veri seti.
- **Kaynaklar:**
    - AÃ§Ä±k kaynak veri setleri (FFHQ, CelebA, FairFace).
    - GÃ¶nÃ¼llÃ¼ kullanÄ±cÄ± verileri (KVKK/GDPR uyumlu).
    - Tarihsel/ArÅŸiv fotoÄŸraflarÄ± (Ã¼nlÃ¼ liderler, dÃ¼ÅŸÃ¼nÃ¼rler).
- **Ã‡eÅŸitlilik:** FarklÄ± yaÅŸ, cinsiyet, etnik kÃ¶ken ve Ä±ÅŸÄ±k koÅŸullarÄ±.

### 1.2. Etiketleme (Annotation)
- **Fizyonomik Etiketler:** Uzmanlar tarafÄ±ndan belirlenen Ã¶zellikler.
    - Ã–rn: "GeniÅŸ alÄ±n", "Kemerli burun", "AyrÄ±k gÃ¶zler".
- **KiÅŸilik Etiketleri:** Psikolojik test sonuÃ§larÄ± (Big Five, MBTI) ile eÅŸleÅŸtirilmiÅŸ yÃ¼z verileri.
- **Etiketleme AraÃ§larÄ±:**
    
    #### SeÃ§enek 1: CVAT (Computer Vision Annotation Tool)
    - **AÃ§Ä±klama:** Intel tarafÄ±ndan geliÅŸtirilen aÃ§Ä±k kaynaklÄ±, web tabanlÄ± gÃ¶rÃ¼ntÃ¼ ve video etiketleme platformu.
    - **Avantajlar:**
        - Ã‡ok kullanÄ±cÄ±lÄ± ve iÅŸbirliÄŸine dayalÄ± Ã§alÄ±ÅŸma imkanÄ±.
        - Polygon, polyline, point, bounding box gibi zengin etiketleme araÃ§larÄ±.
        - Video etiketleme desteÄŸi (frame-by-frame).
        - REST API ile otomasyon desteÄŸi.
        - Kalite kontrol ve gÃ¶rev yÃ¶netimi Ã¶zellikleri.
        - Etiket interpolasyonu (video iÃ§in otomatik ara frame etiketleme).
    - **Dezavantajlar:**
        - Sunucu kurulumu ve bakÄ±mÄ± gerektirir.
        - Ä°lk kurulum karmaÅŸÄ±k olabilir.
    - **KullanÄ±m Senaryosu:** Ekip Ã§alÄ±ÅŸmasÄ±, bÃ¼yÃ¼k Ã¶lÃ§ekli veri seti etiketleme, profesyonel kullanÄ±m.
    
    #### SeÃ§enek 2: LabelImg
    - **AÃ§Ä±klama:** Hafif ve masaÃ¼stÃ¼ tabanlÄ± gÃ¶rÃ¼ntÃ¼ etiketleme aracÄ±.
    - **Avantajlar:**
        - Basit ve kullanÄ±mÄ± kolay arayÃ¼z.
        - Kurulum gerektirmez (standalone exe).
        - HÄ±zlÄ± baÅŸlangÄ±Ã§ iÃ§in ideal.
        - Pascal VOC ve YOLO formatlarÄ±nda Ã§Ä±ktÄ±.
    - **Dezavantajlar:**
        - SÄ±nÄ±rlÄ± etiketleme tÃ¼rleri (sadece bounding box).
        - Ã‡ok kullanÄ±cÄ±lÄ± Ã§alÄ±ÅŸma desteÄŸi yok.
        - Video etiketleme Ã¶zelliÄŸi yok.
        - Landmark/keypoint etiketleme iÃ§in uygun deÄŸil.
    - **KullanÄ±m Senaryosu:** KÃ¼Ã§Ã¼k Ã¶lÃ§ekli projeler, hÄ±zlÄ± prototipleme, tek kullanÄ±cÄ±.
    
    #### SeÃ§enek 3: Ã–zel Etiketleme AracÄ± (Tavsiye Edilen)
    - **AÃ§Ä±klama:** Fizyonomi analizi iÃ§in Ã¶zel geliÅŸtirilmiÅŸ PyQt6 tabanlÄ± masaÃ¼stÃ¼ etiketleme uygulamasÄ±.
    - **Neden GeliÅŸtirilmeli:**
        - Mevcut AnnotationView altyapÄ±sÄ± zaten var.
        - Fizyonomi etiketleme iÃ§in Ã¶zelleÅŸmiÅŸ Ã¶zellikler:
            - MediaPipe ile otomatik Ã¶n-etiketleme.
            - 468 yÃ¼z landmark'Ä±nÄ±n manuel dÃ¼zenlemesi.
            - Fizyonomik bÃ¶lge gruplarÄ± (alÄ±n, gÃ¶z, burun, Ã§ene vb.) iÃ§in Ã¶zel UI.
            - Batch iÅŸleme ve otomatik kaydetme.
        - KullanÄ±cÄ± deneyimi tam kontrolÃ¼nÃ¼z altÄ±nda.
        - Veri formatÄ± ve veritabanÄ± ile tam entegrasyon.
    - **GeliÅŸtirme AdÄ±mlarÄ±:**
        - Mevcut `AnnotationView` Ã¼zerinden standalone mod.
        - Bulk import/export Ã¶zelliÄŸi.
        - Klavye kÄ±sayollarÄ± ile hÄ±zlÄ± etiketleme.
        - Ä°lerleme takibi ve kalite kontrol paneli.
        - Her etiketÃ§i iÃ§in kullanÄ±cÄ± bazlÄ± istatistikler.
    - **Tahmini GeliÅŸtirme SÃ¼resi:** 1-2 hafta.
    
    #### KarÅŸÄ±laÅŸtÄ±rma ve Ã–neri
    
    | Ã–zellik | CVAT | LabelImg | Ã–zel AraÃ§ |
    |---------|------|----------|-----------|
    | Landmark Etiketleme | âœ… Var | âŒ Yok | âœ… Optimize |
    | Otomatik Ã–n-Etiketleme | âš ï¸ Model entegrasyonu gerekir | âŒ Yok | âœ… MediaPipe entegre |
    | KullanÄ±m KolaylÄ±ÄŸÄ± | âš ï¸ Orta | âœ… Ã‡ok Kolay | âœ… Projeye Ã–zel |
    | Ã‡ok KullanÄ±cÄ±lÄ± | âœ… Var | âŒ Yok | âš ï¸ Eklenebilir |
    | Maliyet | ğŸ†“ Ãœcretsiz | ğŸ†“ Ãœcretsiz | ğŸ’° GeliÅŸtirme zamanÄ± |
    
    **Final Ã–neri:** Ä°lk aÅŸamada **LabelImg** veya mevcut **AnnotationView** ile kÃ¼Ã§Ã¼k bir pilot veri seti (~100 gÃ¶rÃ¼ntÃ¼) etiketleyip etiketleme iÅŸ akÄ±ÅŸÄ±nÄ± test edin. ArdÄ±ndan daha bÃ¼yÃ¼k Ã¶lÃ§ekli etiketleme iÃ§in **Ã–zel Etiketleme AracÄ±**nÄ± geliÅŸtirin veya ekip Ã§alÄ±ÅŸmasÄ± gerekiyorsa **CVAT** kurulumunu yapÄ±n.

## Faz 2: Model GeliÅŸtirme ve EÄŸitimi (2-3 Ay)

Mevcut kural tabanlÄ± (geometrik) sistemden, derin Ã¶ÄŸrenme tabanlÄ± sisteme geÃ§iÅŸ.

### 2.1. YÃ¼z Ã–zellik Ã‡Ä±karÄ±mÄ± (Feature Extraction)

#### Mevcut Sistem vs Hedef Sistem

| Ã–zellik | Mevcut (MediaPipe) | Hedef (Deep Learning) |
|---------|-------------------|----------------------|
| YÃ¶ntem | Geometrik landmark'lar (468 nokta) | CNN/Transformer embeddings |
| Ã–zellik TÃ¼rÃ¼ | Koordinatlar ve mesafeler | YÃ¼ksek seviye soyut Ã¶zellikler |
| Boyut | ~1400 deÄŸer (468Ã—3) | 512-2048 boyutlu vektÃ¶r |
| Avantajlar | HÄ±zlÄ±, yorumlanabilir | Daha gÃ¼Ã§lÃ¼ genelleme, doku/renk bilgisi |
| Dezavantajlar | SÄ±nÄ±rlÄ± Ã¶zellik Ã§eÅŸitliliÄŸi | Daha fazla hesaplama gÃ¼cÃ¼ gerektirir |

#### Ã–nerilen Model Mimarileri

##### SeÃ§enek 1: ResNet50 (Basit ve Etkili)
- **AÃ§Ä±klama:** Microsoft tarafÄ±ndan geliÅŸtirilen 50 katmanlÄ± residual network.
- **Ã‡Ä±ktÄ±:** 2048 boyutlu embedding vektÃ¶rÃ¼.
- **Transfer Learning:** ImageNet Ã¶n-eÄŸitimli model kullanÄ±labilir.
- **Avantajlar:**
    - KanÄ±tlanmÄ±ÅŸ baÅŸarÄ± oranÄ±.
    - PyTorch/TensorFlow'da hazÄ±r model var.
    - Orta seviye hesaplama gÃ¼cÃ¼ yeterli.
- **KullanÄ±m:**
    ```python
    import torch
    from torchvision.models import resnet50, ResNet50_Weights
    
    # Ã–n-eÄŸitimli ResNet50 yÃ¼kle
    model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
    # Son katmanÄ± kaldÄ±r, embedding al
    model = torch.nn.Sequential(*list(model.children())[:-1])
    model.eval()
    
    # YÃ¼z fotoÄŸrafÄ±ndan embedding Ã§Ä±kar
    with torch.no_grad():
        embedding = model(face_tensor)  # [1, 2048]
    ```

##### SeÃ§enek 2: EfficientNet-B4 (Daha Hafif ve HÄ±zlÄ±)
- **AÃ§Ä±klama:** Google tarafÄ±ndan geliÅŸtirilen verimli model mimarisi.
- **Ã‡Ä±ktÄ±:** 1792 boyutlu embedding.
- **Avantajlar:**
    - ResNet50'den 5x daha az parametre.
    - Daha hÄ±zlÄ± inference.
    - Mobil/masaÃ¼stÃ¼ uygulamalar iÃ§in ideal.
- **KullanÄ±m Senaryosu:** GerÃ§ek zamanlÄ± analiz gerekiyorsa.

##### SeÃ§enek 3: ArcFace / MagFace (YÃ¼z TanÄ±ma Ä°Ã§in Optimize)
- **AÃ§Ä±klama:** YÃ¼z tanÄ±ma iÃ§in Ã¶zel geliÅŸtirilmiÅŸ loss fonksiyonlarÄ± ve modeller.
- **Ã‡Ä±ktÄ±:** 512 boyutlu normalleÅŸtirilmiÅŸ embedding.
- **Avantajlar:**
    - AynÄ± kiÅŸinin farklÄ± pozlarÄ±nÄ± yakÄ±n vektÃ¶rler olarak temsil eder.
    - FarklÄ± kiÅŸileri maksimum ayrÄ±ÅŸtÄ±rma.
    - InsightFace kÃ¼tÃ¼phanesi ile kullanÄ±ma hazÄ±r.
- **KullanÄ±m:**
    ```python
    from insightface.app import FaceAnalysis
    
    app = FaceAnalysis(providers=['CPUExecutionProvider'])
    app.prepare(ctx_id=0, det_size=(640, 640))
    
    faces = app.get(img)
    if faces:
        embedding = faces[0].embedding  # [512,]
    ```
- **UyarÄ±:** Fizyonomi iÃ§in kimlik bilgisi yerine yapÄ±sal Ã¶zellikler Ã¶nemli, bu yÃ¼zden ArcFace + ek Ã¶zellik Ã§Ä±karÄ±mÄ± kombinasyonu Ã¶nerilir.

##### SeÃ§enek 4: Vision Transformer (ViT) - En GeliÅŸmiÅŸ
- **AÃ§Ä±klama:** Transformer mimarisi gÃ¶rÃ¼ntÃ¼ iÅŸlemeye uyarlanmÄ±ÅŸ hali.
- **Ã‡Ä±ktÄ±:** 768-1024 boyutlu embedding.
- **Avantajlar:**
    - En yÃ¼ksek doÄŸruluk potansiyeli.
    - Global iliÅŸkileri daha iyi yakalar.
    - Pretrained modeller (Google ViT, DeiT).
- **Dezavantajlar:**
    - Daha fazla veri ve hesaplama gÃ¼cÃ¼ gerektirir.
    - Daha yavaÅŸ inference.
- **Ã–neri:** EÄŸer yeterli veri varsa (~50K+ etiketli gÃ¶rÃ¼ntÃ¼) tercih edilebilir.

#### Hibrit YaklaÅŸÄ±m (Ã–nerilen)
```
MediaPipe Landmarks (Geometrik) + Deep Learning Embeddings (Semantik)
         â†“                                    â†“
    [1400 deÄŸer]                         [512 deÄŸer]
         â†“                                    â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ BirleÅŸtir â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                   [1912 boyutlu Ã¶zellik vektÃ¶rÃ¼]
                            â†“
                  Downstream Task (KiÅŸilik Tahmini)
```

**Avantajlar:**
- MediaPipe'Ä±n hassasiyeti + Deep Learning'in genelleme gÃ¼cÃ¼.
- Geometrik anormallikler + gÃ¶rsel doku birlikte deÄŸerlendirilebilir.

---


### 2.2. Ã‡oklu GÃ¶rev Ã–ÄŸrenimi (Multi-Task Learning)

#### Neden Ã‡oklu GÃ¶rev Ã–ÄŸrenimi?
Tek bir modelin aynÄ± anda birden fazla gÃ¶revi Ã¶ÄŸrenmesi:
- **Verimlilik:** Tek model, birden fazla iÅŸ gÃ¶rdÃ¼ÄŸÃ¼ iÃ§in kaynak tasarrufu.
- **Genelleme:** GÃ¶revler birbirini destekler (Ã¶rn: yaÅŸ tahmini, yÃ¼z ÅŸekli tespitine yardÄ±mcÄ± olur).
- **Ã–zellik PaylaÅŸÄ±mÄ±:** Alt katmanlar ortak Ã¶zellikler Ã¶ÄŸrenir.

#### Model Mimarisi

```
                    Input: YÃ¼z GÃ¶rÃ¼ntÃ¼sÃ¼ (224Ã—224Ã—3)
                              â†“
                    Backbone (ResNet50 / EfficientNet)
                    Shared Feature Extractor
                              â†“
                    Feature Vector [2048-dim]
                              â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â†“                   â†“                   â†“
    Task Head 1         Task Head 2         Task Head 3
    YÃ¼z Åekli          YaÅŸ & Cinsiyet      Mikro Ä°fadeler
    SÄ±nÄ±flandÄ±rma       Regresyon          SÄ±nÄ±flandÄ±rma
          â†“                   â†“                   â†“
    [Oval, Kare,        [YaÅŸ: 0-100,        [Mutlu, Ciddi,
     ÃœÃ§gen, vb.]         Cinsiyet: M/F]      Sinirgial, vb.]
```

#### Task DetaylarÄ±

##### Task 1: YÃ¼z Åekli SÄ±nÄ±flandÄ±rmasÄ±
- **Kategoriler:** Oval, Yuvarlak, Kare, ÃœÃ§gen, Uzun, Elmas (6 sÄ±nÄ±f).
- **Loss:** CrossEntropyLoss
- **Metrik:** Accuracy, F1-Score
- **Ã‡Ä±ktÄ±:** Softmax olasÄ±lÄ±klarÄ±

##### Task 2: YaÅŸ ve Cinsiyet Tahmini
- **YaÅŸ:** Regresyon gÃ¶revi (0-100 arasÄ±).
    - Loss: MSE (Mean Squared Error) veya MAE (Mean Absolute Error)
    - Metrik: MAE (ortalama Â±5 yaÅŸ doÄŸruluÄŸu hedefi)
- **Cinsiyet:** Binary sÄ±nÄ±flandÄ±rma (Erkek/KadÄ±n).
    - Loss: Binary CrossEntropy
    - Metrik: Accuracy

##### Task 3: Mikro Ä°fade Analizi
- **Kategoriler:** NÃ¶tr, Mutlu, ÃœzgÃ¼n, Ciddi, OdaklanmÄ±ÅŸ, Sinirli (6 sÄ±nÄ±f).
- **Loss:** CrossEntropyLoss
- **Metrik:** Accuracy, Confusion Matrix
- **Ã–nemli Not:** Bu gÃ¶rev, Ã§ekilen fotoÄŸrafÄ±n anÄ±ndaki ifadeyi deÄŸil, kiÅŸinin genel yÃ¼z yapÄ±sÄ±ndan kaynaklanan doÄŸal ifade eÄŸilimini Ã¶ÄŸrenmelidir.

#### Toplam Loss Fonksiyonu
```python
total_loss = (
    Î±â‚ * loss_face_shape +      # Î±â‚ = 0.3
    Î±â‚‚ * loss_age +              # Î±â‚‚ = 0.2
    Î±â‚ƒ * loss_gender +           # Î±â‚ƒ = 0.2
    Î±â‚„ * loss_expression         # Î±â‚„ = 0.3
)
```
**AÄŸÄ±rlÄ±klar (Î±):** Her gÃ¶revin Ã¶nemine gÃ¶re ayarlanÄ±r (hiperparametre).

#### PyTorch Implementasyonu (Ã–rnek)
```python
import torch
import torch.nn as nn
from torchvision.models import resnet50

class MultiTaskFaceModel(nn.Module):
    def __init__(self):
        super().__init__()
        # Shared backbone
        backbone = resnet50(pretrained=True)
        self.features = nn.Sequential(*list(backbone.children())[:-1])
        
        # Task heads
        self.head_shape = nn.Linear(2048, 6)      # 6 yÃ¼z ÅŸekli
        self.head_age = nn.Linear(2048, 1)         # YaÅŸ regresyonu
        self.head_gender = nn.Linear(2048, 2)      # Cinsiyet
        self.head_expression = nn.Linear(2048, 6)  # 6 ifade
    
    def forward(self, x):
        features = self.features(x).flatten(1)
        return {
            'shape': self.head_shape(features),
            'age': self.head_age(features),
            'gender': self.head_gender(features),
            'expression': self.head_expression(features)
        }
```

#### EÄŸitim Stratejisi
1. **BaÅŸlangÄ±Ã§:** Backbone'u dondur (freeze), sadece task head'leri eÄŸit (5 epoch).
2. **Fine-tuning:** TÃ¼m modeli dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme hÄ±zÄ±yla eÄŸit (20 epoch).
3. **Learning Rate:** 1e-4 (AdamW optimizer).
4. **Batch Size:** 32-64 (GPU belleÄŸine gÃ¶re).
5. **Data Augmentation:**
    - Random horizontal flip
    - Color jitter (Â±10% brightness/contrast)
    - Random rotation (Â±15Â°)

---

### 2.3. Fizyonomi Modeli (PhysiognomyNet)

#### Genel BakÄ±ÅŸ
Bu model, **yÃ¼z Ã¶zelliklerinden kiÅŸilik puanlarÄ±nÄ± tahmin etme** gibi kritik ve hassas bir gÃ¶revi Ã¼stlenir.

> [!WARNING]
> **Etik UyarÄ±:** Fizyonomi biliminin geÃ§erliliÄŸi tartÄ±ÅŸmalÄ±dÄ±r. Bu model, eÄŸlence/kiÅŸisel geliÅŸim amaÃ§lÄ± tasarlanmalÄ± ve karar verme sÃ¼reÃ§lerinde (iÅŸe alÄ±m, kredi onayÄ± vb.) kullanÄ±lmamalÄ±dÄ±r.

#### Model Mimarisi

```
Input: YÃ¼z Embedding [512-dim] (ArcFace'den)
      + Geometrik Ã–zellikler [1400-dim] (MediaPipe'dan)
            â†“
      Concatenate â†’ [1912-dim]
            â†“
      Dense Layer (1024) + ReLU + Dropout(0.3)
            â†“
      Dense Layer (512) + ReLU + Dropout(0.3)
            â†“
      Dense Layer (256) + ReLU
            â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“        â†“        â†“        â†“
 Zeka    Duygu    Ä°rade   Sosyal
  Head     Head     Head     Head
   â†“        â†“        â†“        â†“
 [0-100] [0-100] [0-100]  [0-100]
```

#### Ã‡Ä±ktÄ± BoyutlarÄ± (Ã–nerilen)
Her kiÅŸilik boyutu iÃ§in ayrÄ± bir tahmin:

1. **Zeka Seviyesi** (0-100): Analitik dÃ¼ÅŸÃ¼nme potansiyeli.
2. **Duygusal YoÄŸunluk** (0-100): Empatik/duygusal tepki eÄŸilimi.
3. **Ä°rade GÃ¼cÃ¼** (0-100): KararlÄ±lÄ±k ve dayanÄ±klÄ±lÄ±k.
4. **Sosyal AÃ§Ä±klÄ±k** (0-100): DÄ±ÅŸadÃ¶nÃ¼klÃ¼k ve sosyalleÅŸme eÄŸilimi.

> [!TIP]
> Bu boyutlar Big Five kiÅŸilik modeline (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) eÅŸlenebilir.

#### EÄŸitim Veri KaynaklarÄ±

##### SeÃ§enek 1: Psikolojik Test EÅŸleÅŸtirmesi (Ä°deal)
- **YÃ¶ntem:** GÃ¶nÃ¼llÃ¼lerden yÃ¼z fotoÄŸrafÄ± + psikolojik test sonuÃ§larÄ± toplamak.
- **Testler:**
    - Big Five Personality Test (OCEAN modeli)
    - MBTI (Myers-Briggs Type Indicator)
    - IQ testleri (Raven's Progressive Matrices vb.)
- **Veri MiktarÄ±:** Minimum 5000 eÅŸleÅŸtirilmiÅŸ Ã¶rnek.
- **Zorluk:** Veri toplama maliyetli ve uzun sÃ¼rebilir.

##### SeÃ§enek 2: Self-Assessment Etiketleme
- **YÃ¶ntem:** KullanÄ±cÄ±larÄ±n kendi kiÅŸilik Ã¶zelliklerini 0-100 skalasÄ±nda deÄŸerlendirmeleri.
- **Avantajlar:** HÄ±zlÄ± veri toplama.
- **Dezavantajlar:** Subjektif ve gÃ¼venilir olmayabilir.

##### SeÃ§enek 3: Uzman EtiketÃ§iler
- **YÃ¶ntem:** Psikologlar veya fizyonomi uzmanlarÄ±nÄ±n fotoÄŸraflarÄ± deÄŸerlendirmesi.
- **Avantajlar:** Daha tutarlÄ± etiketler.
- **Dezavantajlar:** PahalÄ± ve yavaÅŸ.

#### Loss Fonksiyonu
```python
# Regresyon gÃ¶revi (0-100 arasÄ± tahmin)
loss = nn.MSELoss()

# Veya daha robust:
loss = nn.SmoothL1Loss()  # Huber Loss - outlier'lara daha az duyarlÄ±
```

#### EÄŸitim SÃ¼reci

1. **Veri HazÄ±rlÄ±ÄŸÄ±:**
    - Normalize et: Her kiÅŸilik boyutunu [0, 1] aralÄ±ÄŸÄ±na getir.
    - Train/Val/Test split: 70% / 15% / 15%
    - K-Fold Cross Validation (k=5) gÃ¼venilirlik iÃ§in.

2. **Model EÄŸitimi:**
    ```python
    # Hiperparametreler
    epochs = 50
    batch_size = 64
    learning_rate = 1e-4
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    ```

3. **Regularization:**
    - Dropout: 0.3-0.4
    - L2 Weight Decay: 1e-5
    - Early Stopping: Validation loss 5 epoch artmazsa dur.

4. **Metrikler:**
    - **MAE (Mean Absolute Error):** Ortalama hata (hedef: <10 puan).
    - **Pearson Korelasyon:** GerÃ§ek vs tahmin korelasyonu (hedef: >0.6).
    - **RÂ² Score:** AÃ§Ä±klanan varyans (hedef: >0.4).

#### Model Validasyonu ve A/B Testi
- **KullanÄ±cÄ± Geri Bildirimi:** "Bu analiz size ne kadar uyuyor? (1-5)"
- **Uzman DeÄŸerlendirmesi:** PsikologlarÄ±n sonuÃ§larÄ± deÄŸerlendirmesi.
- **KarÅŸÄ±laÅŸtÄ±rma:** Mevcut geometrik sistem vs PhysiognomyNet karÅŸÄ±laÅŸtÄ±rmasÄ±.

#### Ã–rnek Kod: PhysiognomyNet
```python
import torch.nn as nn

class PhysiognomyNet(nn.Module):
    def __init__(self, input_dim=1912, hidden_dims=[1024, 512, 256], num_traits=4):
        super().__init__()
        
        layers = []
        prev_dim = input_dim
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.3)
            ])
            prev_dim = hidden_dim
        
        self.shared_layers = nn.Sequential(*layers)
        
        # Her kiÅŸilik boyutu iÃ§in ayrÄ± head
        self.trait_heads = nn.ModuleList([
            nn.Linear(hidden_dims[-1], 1) for _ in range(num_traits)
        ])
    
    def forward(self, x):
        features = self.shared_layers(x)
        # Ã‡Ä±ktÄ±lar [0, 100] arasÄ±nda olmalÄ±
        traits = [torch.sigmoid(head(features)) * 100 for head in self.trait_heads]
        return torch.cat(traits, dim=1)  # [batch_size, 4]
```

#### Beklenen SonuÃ§lar
- **Ä°lk Versiyon (Baseline):** MAE ~15-20 puan, RÂ² ~0.3
- **Optimized Model:** MAE ~8-12 puan, RÂ² ~0.5-0.6
- **GerÃ§ekÃ§i Beklenti:** Tam doÄŸruluk mÃ¼mkÃ¼n deÄŸil, ancak genel eÄŸilimleri yakalamak mÃ¼mkÃ¼n.

---

### 2.4. EÄŸitim AltyapÄ±sÄ± ve AraÃ§lar

#### Gerekli DonanÄ±m
- **GPU:** NVIDIA RTX 3060 (12GB) veya Ã¼zeri (Ã¶nerilir: RTX 4090).
- **RAM:** Minimum 16GB, Ã¶nerilir 32GB.
- **Depolama:** 500GB SSD (veri setleri ve checkpoint'ler iÃ§in).

#### YazÄ±lÄ±m YÄ±ÄŸÄ±nÄ±
```
Python 3.10+
â”œâ”€â”€ PyTorch 2.0+ (CUDA 11.8)
â”œâ”€â”€ torchvision
â”œâ”€â”€ tensorboard (eÄŸitim takibi)
â”œâ”€â”€ wandb (W&B - opsiyonel, bulut takip)
â”œâ”€â”€ opencv-python
â”œâ”€â”€ albumentations (data augmentation)
â”œâ”€â”€ scikit-learn (metrikler)
â””â”€â”€ onnx / onnxruntime (model export)
```

#### EÄŸitim Ä°zleme (Monitoring)
```python
# TensorBoard ile kayÄ±t
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter('runs/physiognomy_exp1')
writer.add_scalar('Loss/train', train_loss, epoch)
writer.add_scalar('MAE/validation', val_mae, epoch)
```

#### Checkpoint YÃ¶netimi
```python
# En iyi modeli kaydet
if val_loss < best_val_loss:
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'val_loss': val_loss,
    }, 'checkpoints/best_model.pth')
```

#### Tahmini EÄŸitim SÃ¼releri
| Model | Veri Seti | GPU | Epoch | Toplam SÃ¼re |
|-------|-----------|-----|-------|-------------|
| ResNet50 | 10K gÃ¶rÃ¼ntÃ¼ | RTX 3060 | 30 | ~3 saat |
| EfficientNet-B4 | 10K gÃ¶rÃ¼ntÃ¼ | RTX 3060 | 30 | ~2 saat |
| Multi-Task Model | 10K gÃ¶rÃ¼ntÃ¼ | RTX 3060 | 50 | ~5 saat |
| PhysiognomyNet | 5K+labels | RTX 3060 | 50 | ~2 saat |

## Faz 3: Entegrasyon ve Uygulama (1-2 Ay)

EÄŸitilen modellerin masaÃ¼stÃ¼ uygulamasÄ±na entegrasyonu.

### 3.1. Model Optimizasyonu
- **ONNX Runtime:** Modellerin farklÄ± donanÄ±mlarda hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ± iÃ§in ONNX formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi.
- **Quantization:** Model boyutunu kÃ¼Ã§Ã¼ltmek ve hÄ±zÄ± artÄ±rmak (FP32 -> INT8).

### 3.2. Hibrit Sistem
- **Kural TabanlÄ± + AI:**
    - MediaPipe ile hassas Ã¶lÃ§Ã¼mler (milimetrik analiz).
    - Deep Learning ile genel izlenim ve doku analizi (kÄ±rÄ±ÅŸÄ±klÄ±klar, cilt kalitesi).
- Ä°ki sistemin sonuÃ§larÄ±nÄ±n aÄŸÄ±rlÄ±klÄ± ortalamasÄ± ile nihai rapor oluÅŸturma.

### 3.3. Geri Bildirim DÃ¶ngÃ¼sÃ¼ (Active Learning)
- KullanÄ±cÄ±larÄ±n analiz sonuÃ§larÄ±na verdiÄŸi geri bildirimlerin ("Bu analiz bana uyuyor/uymuyor") toplanmasÄ±.
- Bu verilerin modelleri yeniden eÄŸitmek (Fine-tuning) iÃ§in kullanÄ±lmasÄ±.

## Faz 4: Ä°leri Seviye Ã–zellikler (Gelecek Vizyonu)

### 4.1. 3D YÃ¼z RekonstrÃ¼ksiyonu (GeliÅŸmiÅŸ)
- Tek bir fotoÄŸraftan fotogerÃ§ekÃ§i 3D kafa modeli oluÅŸturma (DECA, 3DDFA_V2).
- Yan profil analizinin 3D model Ã¼zerinden otomatik yapÄ±lmasÄ±.

### 4.2. Zaman Ä°Ã§inde DeÄŸiÅŸim Analizi
- KullanÄ±cÄ±nÄ±n eski ve yeni fotoÄŸraflarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rarak yÃ¼zdeki ve karakterdeki deÄŸiÅŸimlerin analizi.
- "YaÅŸlandÄ±rma" simÃ¼lasyonu ve gelecekteki potansiyel deÄŸiÅŸimler.

### 4.3. Video Analizi
- AnlÄ±k video akÄ±ÅŸÄ± Ã¼zerinden jest, mimik ve mikro ifade analizi.
- KonuÅŸma sÄ±rasÄ±ndaki tutum ve davranÄ±ÅŸ analizi.

## Teknoloji YÄ±ÄŸÄ±nÄ± (Ã–neri)

- **Dil:** Python
- **Framework:** PyTorch (EÄŸitim), ONNX Runtime (Inference)
- **GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme:** OpenCV, Pillow
- **YÃ¼z KÃ¼tÃ¼phaneleri:** MediaPipe, InsightFace, dlib
- **Veri TabanÄ±:** PostgreSQL (VektÃ¶r verileri iÃ§in pgvector eklentisi)
